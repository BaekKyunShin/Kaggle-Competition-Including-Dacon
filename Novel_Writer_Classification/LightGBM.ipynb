{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LightGBM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPmJxk5/lXXrJ4biAtPRD3R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaekKyunShin/Kaggle-Competition-Including-Dacon/blob/master/Novel_Writer_Classification/LightGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6zf4Ghac3sk"
      },
      "source": [
        "# LightGBM\n",
        "\n",
        "function ClickConnect() { var buttons = document.querySelectorAll(\"colab-dialog.yes-no-dialog paper-button#cancel\"); buttons.forEach(function(btn) { btn.click(); }); console.log(\"10분마다 자동 재연결\"); document.querySelector(\"#top-toolbar > colab-connect-button\").click(); } setInterval(ClickConnect,1000*600)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnLczqFkjJFX",
        "outputId": "2cf5d59a-4375-4290-f7a2-3878f4fa8633",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDbCKKSnjUwB"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "# 모델링\n",
        "import lightgbm as gbm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# 기타\n",
        "import os\n",
        "import re\n",
        "import easydict\n",
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnlEuOSaP0_6"
      },
      "source": [
        "# 전역변수 설정\n",
        "args = easydict.EasyDict({ 'chdir': '/content/gdrive/My Drive/colab/Dacon_Novel_Writer_Classification/',\n",
        "                          'train_dir': 'open/train.csv', \n",
        "                          'test_dir': 'open/test_x.csv',\n",
        "                          'submission_dir': 'open/sample_submission.csv',\n",
        "                          'fianl_submission_dir': 'open/submission.csv',\n",
        "\n",
        "                          'vectorizer': 'count',\n",
        "                          'num_boost_round': 20000,\n",
        "                          'early_stopping_rounds': 50,\n",
        "                          'max_len': 100,\n",
        "                          'epochs': 1,\n",
        "                          'learning_rate': 0.01,\n",
        "                          'max_features': 3000,\n",
        "                          'wd': 1e-5,\n",
        "                          'batch_size': 64,\n",
        "                          'folds': KFold(n_splits=5, shuffle=True, random_state=1991),\n",
        "                          })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfDTNW9sjjx8"
      },
      "source": [
        "# 경로 설정\n",
        "os.chdir(args.chdir)\n",
        "\n",
        "# 파일 불러오기\n",
        "train = pd.read_csv(args.train_dir, encoding='utf-8')\n",
        "test = pd.read_csv(args.test_dir, encoding='utf-8')\n",
        "sample_submission = pd.read_csv(args.submission_dir, encoding='utf-8')\n",
        "\n",
        "train.drop('index', axis=1, inplace=True)\n",
        "test.drop('index', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YhNjgM4jnfD",
        "outputId": "e80539f2-44ae-4aa4-e48a-30249bac5ac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "train.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He was almost choking. There was so much, so m...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“Your sister asked for it, I suppose?”</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  author\n",
              "0  He was almost choking. There was so much, so m...       3\n",
              "1             “Your sister asked for it, I suppose?”       2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrO2vDSkjotL",
        "outputId": "9135b619-82db-43cd-8439-97a1c5f5e241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "test.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“Not at all. I think she is one of the most ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  “Not at all. I think she is one of the most ch...\n",
              "1  \"No,\" replied he, with sudden consciousness, \"..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0emzQSbjuHG",
        "outputId": "f60caf4e-c1a1-45ea-f427-02cfcf001d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "sample_submission.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  0  1  2  3  4\n",
              "0      0  0  0  0  0  0\n",
              "1      1  0  0  0  0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDnL4kdiIIQW"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_ez2J3Cj2T1",
        "outputId": "31b2c98b-31dd-4f68-9873-bff4959638ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 불용어\n",
        "basic_stopwords = { \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \n",
        "             \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \n",
        "             \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \n",
        "             \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n",
        "             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n",
        "             \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n",
        "             \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \n",
        "             \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \n",
        "             \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \n",
        "             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n",
        "             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" }\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk_stopwords = set(stopwords.words('english'))\n",
        "\n",
        "final_stopwords = nltk_stopwords.union(basic_stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAhyS5GEj4Za"
      },
      "source": [
        "# 부호를 제거해주는 함수\n",
        "def alpha_num(text):\n",
        "    return re.sub(r'[^A-Za-z0-9 ]', '', text)\n",
        "\n",
        "# 불용어 제거해주는 함수\n",
        "def remove_stopwords(text: str):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in final_stopwords:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "    \n",
        "# 전처리 적용\n",
        "train['text']=train['text'].apply(alpha_num)\n",
        "test['text']=test['text'].apply(alpha_num)\n",
        "train['text'] = train['text'].str.lower()\n",
        "test['text'] = test['text'].str.lower()\n",
        "train['text'] = train['text'].apply(alpha_num).apply(remove_stopwords)\n",
        "test['text'] = test['text'].apply(alpha_num).apply(remove_stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5_EtrEP7NXB"
      },
      "source": [
        "# 단어 개수에 대한 feature 추가\n",
        "\n",
        "train['num_words'] = 0\n",
        "train_num_words_list = []\n",
        "for i, row in train.iterrows():\n",
        "    num_words = len(row['text'].split())\n",
        "    train_num_words_list.append(num_words)\n",
        "\n",
        "test['num_words'] = 0\n",
        "test_num_words_list = []\n",
        "for i, row in test.iterrows():\n",
        "    num_words = len(row['text'].split())\n",
        "    test_num_words_list.append(num_words)\n",
        "\n",
        "train['num_words'] = train_num_words_list\n",
        "test['num_words'] = test_num_words_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N4XeaPINYwx"
      },
      "source": [
        "# Vectorizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIwoIqAWys8w",
        "outputId": "8a847992-35da-43f9-d812-497f3317ee09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Count Vectorizer\n",
        "count_vec = CountVectorizer(ngram_range=(1,2), min_df=5, binary=True, max_features=args.max_features) \n",
        "train_cv = count_vec.fit_transform(train['text'])\n",
        "# train_cv = train_cv.concat(train['num_words'])\n",
        "train_cv = pd.DataFrame(train_cv.tocsr().toarray())\n",
        "train_cv['num_words'] = train['num_words']\n",
        "X_cv = train_cv\n",
        "\n",
        "# CSR 형식으로 변경\n",
        "# X_cv = train_cv.tocsr().toarray()\n",
        "print(\"CountVectorized train dataset shape: \", X_cv.shape)\n",
        "\n",
        "# Test Data에도 동일하게 적용\n",
        "test_cv = count_vec.transform(test['text'])\n",
        "# test_cv = test_cv.concat(test['num_words'])\n",
        "test_cv = pd.DataFrame(test_cv.tocsr().toarray())\n",
        "test_cv['num_words'] = test['num_words']\n",
        "\n",
        "# test_cv = test_cv.tocsr().toarray()\n",
        "print(\"CountVectorized test dataset shape: \", test_cv.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorized train dataset shape:  (54879, 3001)\n",
            "CountVectorized test dataset shape:  (19617, 3001)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYMYW4RaytLh",
        "outputId": "1f543954-29cf-401e-d7d5-07df465291db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TF-IDF Vectorizer\n",
        "tfidf_vec=TfidfVectorizer(ngram_range=(1,2), min_df=3, max_df=0.4, sublinear_tf=True, norm='l2', max_features=args.max_features) \n",
        "train_tfidf=tfidf_vec.fit_transform(train['text'])\n",
        "print(\"TF-IDF Vectorized train dataset shape: \", train_tfidf.toarray().shape)\n",
        "\n",
        "# CSR 형식으로 변경\n",
        "X_tfidf = train_tfidf.tocsr().toarray()\n",
        "\n",
        "# Test Data에도 동일하게 적용\n",
        "test_tfidf = tfidf_vec.transform(test['text'])\n",
        "test_tfidf = test_tfidf.tocsr().toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF-IDF Vectorized train dataset shape:  (54879, 3000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RqVxiXJ4E_Q"
      },
      "source": [
        "y = train['author']\n",
        "if args.vectorizer == 'tf-idf':\n",
        "    dtest = test_tfidf\n",
        "elif args.vectorizer == 'count':\n",
        "    dtest = test_cv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izGNLDWldlb4"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfvmMaFV2hdm"
      },
      "source": [
        "Dparam = {'objective' : 'multiclass',\n",
        "          'boosting_type': 'gbdt',\n",
        "          'num_class': len(np.unique(y)),\n",
        "          'metric' : 'multi_logloss',\n",
        "          #'max_bin':350,\n",
        "          'max_depth':25,\n",
        "          'min_child_weight': 8,\n",
        "          'bagging_fraction':0.75,\n",
        "          'feature_fraction':0.75,\n",
        "          'lambda_l1':0.3,\n",
        "          'lambda_l2':0.7,\n",
        "          'num_leaves':31} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVq6ydST2hIh",
        "outputId": "a1773065-c748-470f-cc04-0ea5eb0d3bf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Training Model...\")\n",
        "\n",
        "FOLDS = args.folds.split(X_cv)\n",
        "oof_preds = np.zeros((train.shape[0], 5))\n",
        "preds = np.zeros((test.shape[0], 5))\n",
        "\n",
        "for n_fold, (trn_idx, val_idx) in enumerate(FOLDS):\n",
        "    dtrain = gbm.Dataset(X_cv.iloc[trn_idx], y[trn_idx])\n",
        "    dval = gbm.Dataset(X_cv.iloc[val_idx], y[val_idx])\n",
        "    m_gbm = gbm.train(params=Dparam, train_set=dtrain, num_boost_round=args.num_boost_round, valid_sets=[dtrain, dval], valid_names=['train', 'valid'], early_stopping_rounds=args.early_stopping_rounds, verbose_eval=50)\n",
        "    oof_preds[val_idx] = m_gbm.predict(X_cv.iloc[val_idx])\n",
        "    preds += m_gbm.predict(dtest) / args.folds.n_splits\n",
        "    print('Fold %2d log_loss : %.6f' % (n_fold + 1, log_loss(y.iloc[val_idx], oof_preds[val_idx])))\n",
        "    del dtrain, dval\n",
        "    gc.collect()\n",
        "    \n",
        "print('Full log_loss score %.6f' % log_loss(y, oof_preds))   \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Model...\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttrain's multi_logloss: 1.06711\tvalid's multi_logloss: 1.10508\n",
            "[100]\ttrain's multi_logloss: 0.942118\tvalid's multi_logloss: 1.00429\n",
            "[150]\ttrain's multi_logloss: 0.871029\tvalid's multi_logloss: 0.952655\n",
            "[200]\ttrain's multi_logloss: 0.821347\tvalid's multi_logloss: 0.919895\n",
            "[250]\ttrain's multi_logloss: 0.783282\tvalid's multi_logloss: 0.896911\n",
            "[300]\ttrain's multi_logloss: 0.752728\tvalid's multi_logloss: 0.879723\n",
            "[350]\ttrain's multi_logloss: 0.727708\tvalid's multi_logloss: 0.867085\n",
            "[400]\ttrain's multi_logloss: 0.706204\tvalid's multi_logloss: 0.856929\n",
            "[450]\ttrain's multi_logloss: 0.687668\tvalid's multi_logloss: 0.849185\n",
            "[500]\ttrain's multi_logloss: 0.67136\tvalid's multi_logloss: 0.84289\n",
            "[550]\ttrain's multi_logloss: 0.657109\tvalid's multi_logloss: 0.838286\n",
            "[600]\ttrain's multi_logloss: 0.643933\tvalid's multi_logloss: 0.834457\n",
            "[650]\ttrain's multi_logloss: 0.632136\tvalid's multi_logloss: 0.831422\n",
            "[700]\ttrain's multi_logloss: 0.621425\tvalid's multi_logloss: 0.829283\n",
            "[750]\ttrain's multi_logloss: 0.611598\tvalid's multi_logloss: 0.827645\n",
            "[800]\ttrain's multi_logloss: 0.602441\tvalid's multi_logloss: 0.826147\n",
            "[850]\ttrain's multi_logloss: 0.593988\tvalid's multi_logloss: 0.825142\n",
            "[900]\ttrain's multi_logloss: 0.586112\tvalid's multi_logloss: 0.824567\n",
            "[950]\ttrain's multi_logloss: 0.578649\tvalid's multi_logloss: 0.824076\n",
            "[1000]\ttrain's multi_logloss: 0.571671\tvalid's multi_logloss: 0.82424\n",
            "Early stopping, best iteration is:\n",
            "[950]\ttrain's multi_logloss: 0.578649\tvalid's multi_logloss: 0.824076\n",
            "Fold  1 log_loss : 0.824076\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttrain's multi_logloss: 1.06734\tvalid's multi_logloss: 1.10694\n",
            "[100]\ttrain's multi_logloss: 0.94125\tvalid's multi_logloss: 1.00637\n",
            "[150]\ttrain's multi_logloss: 0.86933\tvalid's multi_logloss: 0.956253\n",
            "[200]\ttrain's multi_logloss: 0.819409\tvalid's multi_logloss: 0.92415\n",
            "[250]\ttrain's multi_logloss: 0.781192\tvalid's multi_logloss: 0.902026\n",
            "[300]\ttrain's multi_logloss: 0.750325\tvalid's multi_logloss: 0.885838\n",
            "[350]\ttrain's multi_logloss: 0.725182\tvalid's multi_logloss: 0.873726\n",
            "[400]\ttrain's multi_logloss: 0.70331\tvalid's multi_logloss: 0.864341\n",
            "[450]\ttrain's multi_logloss: 0.684809\tvalid's multi_logloss: 0.857518\n",
            "[500]\ttrain's multi_logloss: 0.668374\tvalid's multi_logloss: 0.851723\n",
            "[550]\ttrain's multi_logloss: 0.653754\tvalid's multi_logloss: 0.847445\n",
            "[600]\ttrain's multi_logloss: 0.640402\tvalid's multi_logloss: 0.84444\n",
            "[650]\ttrain's multi_logloss: 0.62857\tvalid's multi_logloss: 0.842018\n",
            "[700]\ttrain's multi_logloss: 0.617617\tvalid's multi_logloss: 0.840372\n",
            "[750]\ttrain's multi_logloss: 0.607709\tvalid's multi_logloss: 0.839401\n",
            "[800]\ttrain's multi_logloss: 0.598404\tvalid's multi_logloss: 0.838484\n",
            "[850]\ttrain's multi_logloss: 0.58994\tvalid's multi_logloss: 0.838255\n",
            "[900]\ttrain's multi_logloss: 0.581827\tvalid's multi_logloss: 0.83818\n",
            "Early stopping, best iteration is:\n",
            "[888]\ttrain's multi_logloss: 0.583686\tvalid's multi_logloss: 0.837936\n",
            "Fold  2 log_loss : 0.837936\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttrain's multi_logloss: 1.0691\tvalid's multi_logloss: 1.10036\n",
            "[100]\ttrain's multi_logloss: 0.944173\tvalid's multi_logloss: 0.998222\n",
            "[150]\ttrain's multi_logloss: 0.872857\tvalid's multi_logloss: 0.945726\n",
            "[200]\ttrain's multi_logloss: 0.823366\tvalid's multi_logloss: 0.913488\n",
            "[250]\ttrain's multi_logloss: 0.785256\tvalid's multi_logloss: 0.890618\n",
            "[300]\ttrain's multi_logloss: 0.754488\tvalid's multi_logloss: 0.874553\n",
            "[350]\ttrain's multi_logloss: 0.729018\tvalid's multi_logloss: 0.861905\n",
            "[400]\ttrain's multi_logloss: 0.707431\tvalid's multi_logloss: 0.852129\n",
            "[450]\ttrain's multi_logloss: 0.688928\tvalid's multi_logloss: 0.845221\n",
            "[500]\ttrain's multi_logloss: 0.672369\tvalid's multi_logloss: 0.839533\n",
            "[550]\ttrain's multi_logloss: 0.657608\tvalid's multi_logloss: 0.83585\n",
            "[600]\ttrain's multi_logloss: 0.64421\tvalid's multi_logloss: 0.832541\n",
            "[650]\ttrain's multi_logloss: 0.632559\tvalid's multi_logloss: 0.829792\n",
            "[700]\ttrain's multi_logloss: 0.621828\tvalid's multi_logloss: 0.827962\n",
            "[750]\ttrain's multi_logloss: 0.611791\tvalid's multi_logloss: 0.826426\n",
            "[800]\ttrain's multi_logloss: 0.602593\tvalid's multi_logloss: 0.825591\n",
            "[850]\ttrain's multi_logloss: 0.594029\tvalid's multi_logloss: 0.825067\n",
            "[900]\ttrain's multi_logloss: 0.585866\tvalid's multi_logloss: 0.825068\n",
            "Early stopping, best iteration is:\n",
            "[884]\ttrain's multi_logloss: 0.588355\tvalid's multi_logloss: 0.824872\n",
            "Fold  3 log_loss : 0.824872\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttrain's multi_logloss: 1.06937\tvalid's multi_logloss: 1.09541\n",
            "[100]\ttrain's multi_logloss: 0.943776\tvalid's multi_logloss: 0.995621\n",
            "[150]\ttrain's multi_logloss: 0.872502\tvalid's multi_logloss: 0.944203\n",
            "[200]\ttrain's multi_logloss: 0.822797\tvalid's multi_logloss: 0.911177\n",
            "[250]\ttrain's multi_logloss: 0.785032\tvalid's multi_logloss: 0.888438\n",
            "[300]\ttrain's multi_logloss: 0.754166\tvalid's multi_logloss: 0.872477\n",
            "[350]\ttrain's multi_logloss: 0.728201\tvalid's multi_logloss: 0.859407\n",
            "[400]\ttrain's multi_logloss: 0.706689\tvalid's multi_logloss: 0.849855\n",
            "[450]\ttrain's multi_logloss: 0.68773\tvalid's multi_logloss: 0.842551\n",
            "[500]\ttrain's multi_logloss: 0.67103\tvalid's multi_logloss: 0.837042\n",
            "[550]\ttrain's multi_logloss: 0.656153\tvalid's multi_logloss: 0.832889\n",
            "[600]\ttrain's multi_logloss: 0.642979\tvalid's multi_logloss: 0.829732\n",
            "[650]\ttrain's multi_logloss: 0.631028\tvalid's multi_logloss: 0.827099\n",
            "[700]\ttrain's multi_logloss: 0.620165\tvalid's multi_logloss: 0.82534\n",
            "[750]\ttrain's multi_logloss: 0.610151\tvalid's multi_logloss: 0.823658\n",
            "[800]\ttrain's multi_logloss: 0.600885\tvalid's multi_logloss: 0.822636\n",
            "[850]\ttrain's multi_logloss: 0.59222\tvalid's multi_logloss: 0.821966\n",
            "[900]\ttrain's multi_logloss: 0.584112\tvalid's multi_logloss: 0.821671\n",
            "Early stopping, best iteration is:\n",
            "[888]\ttrain's multi_logloss: 0.585984\tvalid's multi_logloss: 0.821502\n",
            "Fold  4 log_loss : 0.821502\n",
            "Training until validation scores don't improve for 50 rounds.\n",
            "[50]\ttrain's multi_logloss: 1.06638\tvalid's multi_logloss: 1.10768\n",
            "[100]\ttrain's multi_logloss: 0.940037\tvalid's multi_logloss: 1.01063\n",
            "[150]\ttrain's multi_logloss: 0.868322\tvalid's multi_logloss: 0.959705\n",
            "[200]\ttrain's multi_logloss: 0.818853\tvalid's multi_logloss: 0.927542\n",
            "[250]\ttrain's multi_logloss: 0.781017\tvalid's multi_logloss: 0.905108\n",
            "[300]\ttrain's multi_logloss: 0.750164\tvalid's multi_logloss: 0.888845\n",
            "[350]\ttrain's multi_logloss: 0.7247\tvalid's multi_logloss: 0.876536\n",
            "[400]\ttrain's multi_logloss: 0.70329\tvalid's multi_logloss: 0.866716\n",
            "[450]\ttrain's multi_logloss: 0.684554\tvalid's multi_logloss: 0.859623\n",
            "[500]\ttrain's multi_logloss: 0.668154\tvalid's multi_logloss: 0.853774\n",
            "[550]\ttrain's multi_logloss: 0.653615\tvalid's multi_logloss: 0.849455\n",
            "[600]\ttrain's multi_logloss: 0.640447\tvalid's multi_logloss: 0.846213\n",
            "[650]\ttrain's multi_logloss: 0.628666\tvalid's multi_logloss: 0.843379\n",
            "[700]\ttrain's multi_logloss: 0.617675\tvalid's multi_logloss: 0.840964\n",
            "[750]\ttrain's multi_logloss: 0.607809\tvalid's multi_logloss: 0.839496\n",
            "[800]\ttrain's multi_logloss: 0.5984\tvalid's multi_logloss: 0.838457\n",
            "[850]\ttrain's multi_logloss: 0.589918\tvalid's multi_logloss: 0.837968\n",
            "[900]\ttrain's multi_logloss: 0.581921\tvalid's multi_logloss: 0.837514\n",
            "[950]\ttrain's multi_logloss: 0.574502\tvalid's multi_logloss: 0.837585\n",
            "Early stopping, best iteration is:\n",
            "[935]\ttrain's multi_logloss: 0.576703\tvalid's multi_logloss: 0.837406\n",
            "Fold  5 log_loss : 0.837406\n",
            "Full log_loss score 0.829158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9nO-tTZdnne"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx_1UOEZbFZB",
        "outputId": "307999e6-870f-42ac-ed48-27f82b85e0b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sample_submission[['0','1','2','3','4']] = preds\n",
        "sample_submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.017600</td>\n",
              "      <td>0.913231</td>\n",
              "      <td>0.037650</td>\n",
              "      <td>0.028476</td>\n",
              "      <td>0.003043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.125917</td>\n",
              "      <td>0.173701</td>\n",
              "      <td>0.026870</td>\n",
              "      <td>0.053761</td>\n",
              "      <td>0.619751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.859690</td>\n",
              "      <td>0.010200</td>\n",
              "      <td>0.008929</td>\n",
              "      <td>0.001569</td>\n",
              "      <td>0.119612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.025565</td>\n",
              "      <td>0.000393</td>\n",
              "      <td>0.834284</td>\n",
              "      <td>0.001721</td>\n",
              "      <td>0.138037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.340852</td>\n",
              "      <td>0.111684</td>\n",
              "      <td>0.013465</td>\n",
              "      <td>0.114802</td>\n",
              "      <td>0.419197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19612</th>\n",
              "      <td>19612</td>\n",
              "      <td>0.003693</td>\n",
              "      <td>0.995977</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000269</td>\n",
              "      <td>0.000046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19613</th>\n",
              "      <td>19613</td>\n",
              "      <td>0.394639</td>\n",
              "      <td>0.006953</td>\n",
              "      <td>0.004664</td>\n",
              "      <td>0.008440</td>\n",
              "      <td>0.585304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19614</th>\n",
              "      <td>19614</td>\n",
              "      <td>0.024630</td>\n",
              "      <td>0.971721</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.002954</td>\n",
              "      <td>0.000260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19615</th>\n",
              "      <td>19615</td>\n",
              "      <td>0.008659</td>\n",
              "      <td>0.964093</td>\n",
              "      <td>0.017759</td>\n",
              "      <td>0.007966</td>\n",
              "      <td>0.001523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19616</th>\n",
              "      <td>19616</td>\n",
              "      <td>0.103850</td>\n",
              "      <td>0.026296</td>\n",
              "      <td>0.519033</td>\n",
              "      <td>0.242469</td>\n",
              "      <td>0.108352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19617 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index         0         1         2         3         4\n",
              "0          0  0.017600  0.913231  0.037650  0.028476  0.003043\n",
              "1          1  0.125917  0.173701  0.026870  0.053761  0.619751\n",
              "2          2  0.859690  0.010200  0.008929  0.001569  0.119612\n",
              "3          3  0.025565  0.000393  0.834284  0.001721  0.138037\n",
              "4          4  0.340852  0.111684  0.013465  0.114802  0.419197\n",
              "...      ...       ...       ...       ...       ...       ...\n",
              "19612  19612  0.003693  0.995977  0.000015  0.000269  0.000046\n",
              "19613  19613  0.394639  0.006953  0.004664  0.008440  0.585304\n",
              "19614  19614  0.024630  0.971721  0.000435  0.002954  0.000260\n",
              "19615  19615  0.008659  0.964093  0.017759  0.007966  0.001523\n",
              "19616  19616  0.103850  0.026296  0.519033  0.242469  0.108352\n",
              "\n",
              "[19617 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8f25VHJytat"
      },
      "source": [
        "sample_submission.to_csv(args.fianl_submission_dir, index=False, encoding = 'utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}