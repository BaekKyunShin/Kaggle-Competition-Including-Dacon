{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Objective\n\nSentiment analysis is a common use case of NLP where the idea is to classify the tweet as positive, negative or neutral depending upon the text in the tweet. This problem goes a way ahead and expects us to also determine the words in the tweet which decide the polarity of the tweet.\n\n## Understanding the Evaluation Metric\n\nThe metric in this competition is the word-level **Jaccard score**. Jaccard Score is a measure of how dissimilar two sets are.  The lower the distance, the more similar the two strings. The idea is to find the number of common tokens and divide it by the total number of unique tokens. Its expressed in the mathematical terms by,\n\n![](https://images.deepai.org/glossary-terms/jaccard-index-452201.jpg)\n\n![](https://images.deepai.org/glossary-terms/jaccard-index-391304.jpg)\n\n[Source](https://en.wikipedia.org/wiki/Jaccard_index)\n\n**Here is how one can implement the jaccard score in Python:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))\n\n\nSentence_1 = 'Life well spent is life good'\nSentence_2 = 'Life is an art and it is good so far'\n    \njaccard(Sentence_1,Sentence_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Sentence_1 = 'Life well spent is life good'\nSentence_2 = 'Life well spent is life good'\n    \njaccard(Sentence_1,Sentence_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a name=\"imports\"></a>1. Importing the necessary libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\n# text processing libraries\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\n\n# XGBoost\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\n\n# sklearn \nfrom sklearn import model_selection\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import f1_score\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom sklearn.model_selection import GridSearchCV,StratifiedKFold,RandomizedSearchCV\n\n# matplotlib and seaborn for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# File system manangement\nimport os\n\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a name=\"reading\"></a> 2. Reading the datasets"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Training data\ntrain = pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\nprint('Training data shape: ', train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing data \ntest = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\nprint('Testing data shape: ', test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a name=\"eda\"></a> 3. Basic EDA\n\n## Missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Missing values in training set\ntrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The columns denote the following:\n\n* The `textID` of a tweet\n* The `text` of a tweet\n* The s`elected text` which determines the polarity of the tweet\n* `sentiment` of the tweet\n\nThe test dataset doesn't have the selected text column which needs to be identified."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Missing values in test set\ntest.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analysing of the Selected_text Column in the training set\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Positive tweet\nprint(\"Positive Tweet example :\",train[train['sentiment']=='positive']['text'].values[0])\n#negative_text\nprint(\"Negative Tweet example :\",train[train['sentiment']=='negative']['text'].values[0])\n#neutral_text\nprint(\"Neutral tweet example  :\",train[train['sentiment']=='neutral']['text'].values[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A lot of tweets have a neutral sentiment"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(train['sentiment'].value_counts().index,train['sentiment'].value_counts(),palette='rocket')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution of the Sentiment Column in the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(test['sentiment'].value_counts().index,train['sentiment'].value_counts(),palette='rocket')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring positive, negative and neutral text"},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_text = train[train['sentiment'] == 'positive']['selected_text']\nnegative_text = train[train['sentiment'] == 'negative']['selected_text']\nneutral_text = train[train['sentiment'] == 'neutral']['selected_text'].apply(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Positive text\nprint(\"Positive Text example :\",positive_text.values[0])\n#negative_text\nprint(\"Negative Tweet example :\",negative_text.values[0])\n#neutral_text\nprint(\"Neutral tweet example  :\",neutral_text.values[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # <a name=\"processing\"></a> 4. Text Data Preprocessing\n\nCreating a function which does the basic text preprocessing activities including:\n- Make text lowercase, \n- removes text in square brackets,\n- removes links,\n- remove punctuation\n- removes words containing numbers\n- tokenizes\n- removes stopwords\n"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# text preprocessing helper functions\n\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\n\ndef text_preprocessing(text):\n    \"\"\"\n    Cleaning and parsing the text.\n\n    \"\"\"\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    \n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n    combined_text = ' '.join(remove_stopwords)\n    return combined_text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-processed selected text columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_text_clean = positive_text.apply(lambda x: text_preprocessing(x))\nnegative_text_clean = negative_text.apply(lambda x: text_preprocessing(x))\nneutral_text_clean = neutral_text.apply(lambda x: text_preprocessing(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#source of code : https://medium.com/@cristhianboujon/how-to-list-the-most-common-words-from-text-corpus-using-scikit-learn-dad4d0cab41d\ndef get_top_n_words(corpus, n=None):\n    \"\"\"\n    List the top n words in a vocabulary according to occurrence in a text corpus.\n    \"\"\"\n    vec = CountVectorizer().fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"top_words_in_positive_text = get_top_n_words(positive_text_clean)\ntop_words_in_negative_text = get_top_n_words(negative_text_clean)\ntop_words_in_neutral_text = get_top_n_words(neutral_text_clean)\n\np1 = [x[0] for x in top_words_in_positive_text[:10]]\np2 = [x[1] for x in top_words_in_positive_text[:10]]\n\n\nn1 = [x[0] for x in top_words_in_negative_text[1:11]]\nn2 = [x[1] for x in top_words_in_negative_text[1:11]]\n\n\nnu1 = [x[0] for x in top_words_in_neutral_text[1:11]]\nnu2 = [x[1] for x in top_words_in_neutral_text[1:11]]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\n\nfig = go.Figure([go.Bar(x=p1, y=p2, text=p2 )])\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide',title_text='Most common positive_text words')\n\nfig.show()\n\nfig = go.Figure([go.Bar(x=n1, y=n2, text=n2,marker_color='indianred')])\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide',title_text='Most common negative_text words')\n\nfig.show()\n\nfig = go.Figure([go.Bar(x=nu1, y=nu2, text=nu2, marker_color='lightsalmon' )])\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide',title_text='Most common neutral_text words')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Wordclouds\n\nLet's create wordclouds to see which words contribute to which type of polarity."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from wordcloud import WordCloud\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=[26, 8])\nwordcloud1 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(positive_text_clean))\nax1.imshow(wordcloud1)\nax1.axis('off')\nax1.set_title('Positive text',fontsize=40);\n\nwordcloud2 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(negative_text_clean))\nax2.imshow(wordcloud2)\nax2.axis('off')\nax2.set_title('Negative text',fontsize=40);\n\nwordcloud3 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(neutral_text_clean))\nax3.imshow(wordcloud3)\nax3.axis('off')\nax3.set_title('Neutral text',fontsize=40);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"The wordclouds give an idea of the words which might influence the polarity of the tweet."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}